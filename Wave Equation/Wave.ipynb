{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import torch\n",
    "import gc\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import scienceplots\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import traceback\n",
    "from collections import OrderedDict\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Set the random seed for reproducibility\n",
    "seed = 20230808\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# Set the device to GPU if available, otherwise use CPU\n",
    "device = torch.device(\n",
    "    \"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "# Perform garbage collection and empty the GPU cache in PyTorch\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    \"\"\"\n",
    "    A simple neural network class.\n",
    "\n",
    "    Args:\n",
    "        input_size (int): The number of input features.\n",
    "        hidden_size (int): The number of hidden units in each hidden layer.\n",
    "        output_size (int): The number of output features.\n",
    "        depth (int): The number of hidden layers.\n",
    "        ac (torch.nn.Module): The activation function to use for each hidden layer.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size,\n",
    "        hidden_size,\n",
    "        output_size,\n",
    "        depth,\n",
    "        ac=torch.nn.Tanh,\n",
    "    ):\n",
    "        super(NN, self).__init__()\n",
    "\n",
    "        layers = [('input', torch.nn.Linear(input_size, hidden_size))]\n",
    "        layers.append(('input_activation', ac()))\n",
    "        for i in range(depth):\n",
    "            layers.append(\n",
    "                ('hidden_%d' % i, torch.nn.Linear(hidden_size, hidden_size))\n",
    "            )\n",
    "            layers.append(('activation_%d' % i, ac()))\n",
    "        layers.append(('output', torch.nn.Linear(hidden_size, output_size)))\n",
    "\n",
    "        layerDict = OrderedDict(layers)\n",
    "        self.layers = torch.nn.Sequential(layerDict)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass through the network.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): The input tensor of shape (batch_size, input_size).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: The output tensor of shape (batch_size, output_size).\n",
    "        \"\"\"\n",
    "        return self.layers(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop\n",
    "\n",
    "A one-dimensional wave equation is chosen for our experiments, which, in mathematical form, is defined as follows:\n",
    "\n",
    "$$ u_{tt} - u_{xx} = 0$$\n",
    "\n",
    "for this wave equation, its initial conditions and the homogeneous Dirichlet boundary conditions are given, as follows:\n",
    "\n",
    "$$ u(0, x) = \\frac{1}{2} \\sin (\\pi x)$$\n",
    "$$ u_t(0, x) = \\pi \\sin (3 \\pi x)$$\n",
    "$$ u(t, 0) = 0 $$\n",
    "$$ u(t, 0) = 0 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def init_weights(layer):\n",
    "    \"\"\"\n",
    "    Initializes the weights of a layer with Xavier normal initialization.\n",
    "    Args:\n",
    "        layer (torch.nn.Module): The layer to initialize.\n",
    "    \"\"\"\n",
    "    if isinstance(layer, nn.Linear):\n",
    "        torch.nn.init.xavier_normal_(layer.weight)\n",
    "\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self):\n",
    "        # deep neural networks\n",
    "        self.iter = 0\n",
    "        self.model = NN(\n",
    "            input_size=2,\n",
    "            hidden_size=100,\n",
    "            output_size=1,\n",
    "            depth=5,\n",
    "            ac=torch.nn.Tanh\n",
    "        ).to(device)\n",
    "\n",
    "        # use the Glorot normal initializer for initialization\n",
    "        self.model.apply(init_weights)\n",
    "\n",
    "        # The initial conditions, boundary conditions\n",
    "        # with Nu approximating 300\n",
    "        self.h = 0.1\n",
    "        self.k = 0.1\n",
    "        x_u = torch.arange(0, 1 + self.h, self.h)\n",
    "        t_u = torch.arange(0, 1 + self.k, self.k)\n",
    "        c0 = torch.stack(torch.meshgrid(x_u, t_u[0])).reshape(2, -1).T\n",
    "        c1 = torch.rand(300, 2)\n",
    "        c2 = torch.stack(torch.meshgrid(x_u[0], t_u)).reshape(2, -1).T\n",
    "        c3 = torch.stack(torch.meshgrid(x_u[-1], t_u)).reshape(2, -1).T\n",
    "\n",
    "        y_c0 = 1/2*torch.sin(math.pi * c0[:, 0])\n",
    "        y_c1 = 1/2*torch.sin(math.pi*c1[:, 0])*torch.cos(math.pi*c1[:, 1])+1/3*torch.sin(3*math.pi*c1[:, 0])*torch.sin(3*math.pi*c1[:, 1])\n",
    "        y_c2 = torch.zeros(len(c2))\n",
    "        y_c3 = torch.zeros(len(c3))\n",
    "\n",
    "        self.X_u = torch.cat([c0, c1, c2, c3]).to(device)\n",
    "        self.y_u = torch.cat([y_c0, y_c1, y_c2, y_c3]).unsqueeze(1).to(device)\n",
    "        print(f'N_u is {self.X_u.shape[0]}')\n",
    "\n",
    "        # Data in the space-time domain\n",
    "        # with Nf approximating 40000\n",
    "        self.h = 0.1\n",
    "        self.k = 0.1\n",
    "        x_f1 = torch.arange(0, 1 + self.h, self.h)\n",
    "        t_f1 = torch.arange(0, 1 + self.k, self.k)\n",
    "        X_f1 = torch.stack(torch.meshgrid(x_f1, t_f1)).reshape(2, -1).T\n",
    "        X_f2 = torch.rand(40000, 2)\n",
    "        self.X_f = torch.cat([X_f1, X_f2]).to(device)\n",
    "        self.X_f.requires_grad = True\n",
    "        print(f'N_f is {self.X_f.shape[0]}')\n",
    "\n",
    "        # General Loss Function\n",
    "        self.criterion = torch.nn.MSELoss(reduction='mean')\n",
    "\n",
    "        # Two Optimizer\n",
    "        self.optimizer = torch.optim.LBFGS(\n",
    "            self.model.parameters(),\n",
    "            lr=1, \n",
    "            max_iter=50000, \n",
    "            max_eval=50000, \n",
    "            history_size=50,\n",
    "            tolerance_grad=1e-5, \n",
    "            tolerance_change=1.0 * np.finfo(float).eps,\n",
    "            line_search_fn=\"strong_wolfe\",\n",
    "            )\n",
    "\n",
    "        self.adam = torch.optim.Adam(self.model.parameters(), \n",
    "                                     lr=6e-6, \n",
    "                                     weight_decay=1e-6\n",
    "                                    )\n",
    "        self.boss_loss = math.inf\n",
    "\n",
    "    def loss_func(self):\n",
    "        self.adam.zero_grad()\n",
    "        self.optimizer.zero_grad()\n",
    "\n",
    "        # loss using observations of initial and boundary conditions\n",
    "        loss_u = self.criterion(self.model(self.X_u), self.y_u)\n",
    "\n",
    "        # loss based on partial differential equations\n",
    "        u = self.model(self.X_f)\n",
    "        u_X = torch.autograd.grad(\n",
    "            u, self.X_f,\n",
    "            grad_outputs=torch.ones_like(u),\n",
    "            retain_graph=True,\n",
    "            create_graph=True\n",
    "        )[0]\n",
    "\n",
    "        u_x, u_t = u_X[:, 0], u_X[:, 1]\n",
    "\n",
    "        u_xx = torch.autograd.grad(\n",
    "            u_x, self.X_f,\n",
    "            grad_outputs=torch.ones_like(u_x),\n",
    "            retain_graph=True,\n",
    "            create_graph=True\n",
    "        )[0][:, 0]\n",
    "\n",
    "        u_tt = torch.autograd.grad(\n",
    "            u_t, self.X_f,\n",
    "            grad_outputs=torch.ones_like(u_t),\n",
    "            retain_graph=True,\n",
    "            create_graph=True\n",
    "        )[0][:, 1]\n",
    "\n",
    "        loss_f = self.criterion(u_tt - u_xx, u_xx*0)\n",
    "        loss = loss_u + loss_f        \n",
    "        loss.backward()\n",
    "        if self.iter % 100 == 0:\n",
    "            if loss < self.boss_loss:\n",
    "                self.boss_loss = loss\n",
    "                torch.save(self.model.state_dict(), 'boss_model.ckpt')\n",
    "                print(\n",
    "                    'Iter %d, Loss: %.5e, Loss_u: %.5e, Loss_f: %.5e with lowest loss %.5e' % (\n",
    "                        self.iter, loss.item(), loss_u.item(), loss_f.item(), self.boss_loss)\n",
    "                )\n",
    "            \n",
    "        self.iter = self.iter + 1\n",
    "        return loss\n",
    "\n",
    "    def train(self):\n",
    "        self.model.train()\n",
    "        sesese"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer = Trainer()\n",
    "trainer\n",
    "trainer.optimizer.step(trainer.loss_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scienceplots\n",
    "import plotly.express as px\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "# plt.style.use(['ipynb', 'use_mathtext', 'colors5-light', 'science'])\n",
    "# sns.set_style('whitegrid')\n",
    "# sns.set_palette('RdBu')\n",
    "# sns.set(\n",
    "#     rc={'text.usetex': True},\n",
    "#     font='serif',\n",
    "#     font_scale=1.2\n",
    "# )\n",
    "\n",
    "# matplotlib.rcParams['font.sans-serif'] = ['SimHei']\n",
    "# matplotlib.rcParams['font.serif'] = ['SimHei']\n",
    "# sns.set_style('darkgrid', {'font.sans-serif': ['simhei', 'Arial']})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "h = 0.001\n",
    "k = 0.001\n",
    "x = torch.arange(0, 1, h)\n",
    "t = torch.arange(0, 1, k)\n",
    "X = torch.stack(torch.meshgrid(x, t)).reshape(2, -1).T\n",
    "X = X.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ground_truth(X):\n",
    "    x = X[:, 0]\n",
    "    t = X[:, 1]\n",
    "    y = 1/2*torch.sin(torch.pi*x)*torch.cos(torch.pi*t)+1 / \\\n",
    "        3*torch.sin(3*torch.pi*x)*torch.sin(3*torch.pi*t)\n",
    "    return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = NN(input_size=2,\n",
    "           hidden_size=100,\n",
    "           output_size=1,\n",
    "           depth=5,\n",
    "           ac=torch.nn.Tanh).to(device)\n",
    "model.load_state_dict(torch.load('boss_model.ckpt'))\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # y_pred = ground_truth(X).reshape(len(x), len(t)).detach().cpu()\n",
    "    y_pred = model(X).reshape(len(x), len(t)).detach().cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.heatmap(y_pred, cmap='jet')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.arange(0, 1, h).unsqueeze(dim=1).to(device)\n",
    "t = (torch.ones(x.shape)*0.2).to(device)\n",
    "\n",
    "plt.scatter(x.detach().cpu(), model(torch.cat([x, t], dim=1)).detach().cpu())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
